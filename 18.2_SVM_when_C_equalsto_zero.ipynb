{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea4f4fa",
   "metadata": {},
   "source": [
    "# **â—GridSearchCV Can Fail in SVM due to Invalid `C` Parameter**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”´ Core Problem (Root Cause)\n",
    "\n",
    "The **actual error** thrown by scikit-learn is:\n",
    "\n",
    "> InvalidParameterError: The 'C' parameter of SVC must be a float in the range (0.0, inf]. Got 0 instead.\n",
    "\n",
    "### ðŸ‘‰ Interpretation\n",
    "- You **passed `C = 0`** inside the `param_grid` of `GridSearchCV`\n",
    "- `C = 0` is **mathematically invalid** for Support Vector Machines\n",
    "- Hence, model fitting **fails** for those parameter combinations\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ Why is `C = 0` Invalid in SVM?\n",
    "\n",
    "Recall the **Soft-Margin SVM optimization objective**:\n",
    "\n",
    "$$\n",
    "\\min \\; \\frac{1}{2}\\|w\\|^2 + C \\sum_{i=1}^{n} \\xi_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $w$ â†’ weight vector\n",
    "- $\\xi_i$ â†’ slack variables (margin violations)\n",
    "- $C$ â†’ penalty strength for misclassification\n",
    "\n",
    "### Domain of $C$\n",
    "\n",
    "$$\n",
    "C \\in (0, \\infty)\n",
    "$$\n",
    "\n",
    "### âŒ What happens when `C = 0`?\n",
    "\n",
    "- The loss term $C \\sum \\xi_i$ **vanishes**\n",
    "- Objective reduces to:\n",
    "\n",
    "$$\n",
    "\\min \\; \\frac{1}{2}\\|w\\|^2\n",
    "$$\n",
    "\n",
    "- Model **ignores labels entirely**\n",
    "- No classification learning occurs\n",
    "- This is **mathematically meaningless**\n",
    "\n",
    "ðŸ‘‰ Therefore, **scikit-learn explicitly forbids `C = 0`**\n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ Why Do You See a Warning Instead of a Crash?\n",
    "\n",
    "Because **`GridSearchCV` is fault-tolerant by default**.\n",
    "\n",
    "### Internal behavior of `GridSearchCV`:\n",
    "- Tries **all hyperparameter combinations**\n",
    "- If **some combinations fail**:\n",
    "  - Their scores are set to `nan`\n",
    "  - Remaining combinations continue training\n",
    "  - A `FitFailedWarning` is raised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930869c",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Why SVM Becomes Meaningless When `C = 0` (Curated Notes)\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ Role of `C` in Support Vector Machines\n",
    "\n",
    "In **soft-margin SVM**, the optimization problem is:\n",
    "\n",
    "$$\n",
    "\\min_{w,b,\\xi} \\; \\frac{1}{2}\\|w\\|^2 \\;+\\; C \\sum_{i=1}^{n} \\xi_i\n",
    "$$\n",
    "\n",
    "Subject to:\n",
    "\n",
    "$$\n",
    "y_i (w^\\top x_i + b) \\ge 1 - \\xi_i, \\quad \\xi_i \\ge 0\n",
    "$$\n",
    "\n",
    "### Meaning of terms:\n",
    "- $\\frac{1}{2}\\|w\\|^2$ â†’ controls **model complexity** (margin maximization)\n",
    "- $\\xi_i$ â†’ slack variables (margin violations)\n",
    "- $C$ â†’ **penalty strength** for misclassification\n",
    "\n",
    "ðŸ‘‰ **`C` controls how much the model cares about class labels**\n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ What `C` Actually Represents (Intuition)\n",
    "\n",
    "| Value of `C` | Interpretation |\n",
    "|-------------|---------------|\n",
    "| Large $C$ | Strongly penalize errors â†’ fit labels tightly |\n",
    "| Small $C$ | Allow some errors â†’ smoother boundary |\n",
    "| $C = 0$ | Do **not** penalize errors at all |\n",
    "\n",
    "---\n",
    "\n",
    "## 3ï¸âƒ£ Mathematical Effect of Setting `C = 0`\n",
    "\n",
    "Substitute $C = 0$ into the objective:\n",
    "\n",
    "$$\n",
    "\\min_{w,b,\\xi} \\; \\frac{1}{2}\\|w\\|^2 + 0 \\cdot \\sum_{i=1}^{n} \\xi_i\n",
    "$$\n",
    "\n",
    "Which simplifies to:\n",
    "\n",
    "$$\n",
    "\\min_{w,b} \\; \\frac{1}{2}\\|w\\|^2\n",
    "$$\n",
    "\n",
    "ðŸ”´ **The loss term completely disappears**\n",
    "\n",
    "---\n",
    "\n",
    "## 4ï¸âƒ£ Where Do the Labels Go?\n",
    "\n",
    "- Class labels $y_i$ appear only inside constraints:\n",
    "\n",
    "$$\n",
    "y_i (w^\\top x_i + b) \\ge 1 - \\xi_i\n",
    "$$\n",
    "\n",
    "- Slack variables $\\xi_i$ are:\n",
    "  - Non-negative\n",
    "  - **Not penalized anymore** (since $C = 0$)\n",
    "\n",
    "ðŸ‘‰ The optimizer can choose arbitrarily large $\\xi_i$ values  \n",
    "ðŸ‘‰ All constraints become trivially satisfied  \n",
    "ðŸ‘‰ **Labels stop influencing the solution**\n",
    "\n",
    "---\n",
    "\n",
    "## 5ï¸âƒ£ Optimal Solution When `C = 0`\n",
    "\n",
    "The remaining objective is:\n",
    "\n",
    "$$\n",
    "\\min_{w,b} \\; \\frac{1}{2}\\|w\\|^2\n",
    "$$\n",
    "\n",
    "The minimum occurs at:\n",
    "\n",
    "$$\n",
    "w = 0\n",
    "$$\n",
    "\n",
    "Bias $b$ becomes irrelevant.\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£ Resulting Decision Function\n",
    "\n",
    "With $w = 0$:\n",
    "\n",
    "$$\n",
    "f(x) = w^\\top x + b = 0\n",
    "$$\n",
    "\n",
    "Prediction becomes:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\text{sign}(0)\n",
    "$$\n",
    "\n",
    "Effects:\n",
    "- No dependence on input features\n",
    "- No separation between classes\n",
    "- Model predicts a constant output\n",
    "\n",
    "---\n",
    "\n",
    "## 7ï¸âƒ£ Why This Model is Meaningless\n",
    "\n",
    "A valid classifier must:\n",
    "1. Use **input features**\n",
    "2. Use **labels**\n",
    "3. Learn a **relationship** between them\n",
    "\n",
    "With $C = 0$:\n",
    "- Labels do not affect optimization\n",
    "- Constraints are bypassed\n",
    "- Model collapses to $w = 0$\n",
    "\n",
    "ðŸ‘‰ **No learning occurs**\n",
    "\n",
    "---\n",
    "\n",
    "## 8ï¸âƒ£ Geometric Interpretation\n",
    "\n",
    "- Margin becomes infinite\n",
    "- Hyperplane becomes undefined\n",
    "- No support vectors exist\n",
    "- Decision boundary is meaningless\n",
    "\n",
    "---\n",
    "\n",
    "## 9ï¸âƒ£ Real-World Analogy ðŸ§ \n",
    "\n",
    "Think of $C$ as **how strict a teacher is**:\n",
    "\n",
    "- Large $C$ â†’ strict grading\n",
    "- Small $C$ â†’ lenient grading\n",
    "- $C = 0$ â†’ teacher does not care about correctness\n",
    "\n",
    "Result:\n",
    "- Everyone gets the same grade\n",
    "- Answers are ignored\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”Ÿ Why scikit-learn Forbids `C = 0`\n",
    "\n",
    "scikit-learn enforces:\n",
    "\n",
    "$$\n",
    "C \\in (0, \\infty)\n",
    "$$\n",
    "\n",
    "Reason:\n",
    "- Prevents degenerate optimization\n",
    "- Avoids meaningless models\n",
    "- Forces valid learning behavior\n",
    "\n",
    "---\n",
    "\n",
    "## â­ Key Takeaway (Exam-Ready)\n",
    "\n",
    "> **When $C = 0$, SVM removes the loss term, ignores class labels, collapses to $w = 0$, and stops being a classifier.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f0056",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
